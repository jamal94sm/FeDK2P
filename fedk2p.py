{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V28","mount_file_id":"1UDKO09tCO953ylGrSTy0ZyhN3-TCvquJ","authorship_tag":"ABX9TyMeL0Vk/kJasGfKgS2SNgfo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ukW6M_r9KiyB"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import transformers\n","import sklearn.metrics\n","from huggingface_hub import notebook_login\n","import datasets\n","import tensorflow as tf\n","import torch\n","import torch.nn as nn\n","import keras\n","import matplotlib.pyplot as plt\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from PIL import Image\n","import pickle\n","\n","\n","torch.manual_seed(42)\n","np.random.seed(42)\n","\n","# Loading Foundation Model\n","model_name = \"openai/clip-vit-base-patch32\"\n","FM = transformers.CLIPModel.from_pretrained(model_name)\n","processor = transformers.CLIPProcessor.from_pretrained(model_name)\n","tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n","\n","\n","\n","def ddf(x):\n","    x = datasets.Dataset.from_dict(x)\n","    x.set_format(\"torch\")\n","    return x\n","\n","def shuffling(a, b):\n","    return np.random.randint(0, a, b)\n","\n","def normalization(batch):\n","    normal_image = batch[\"img\"] / 255\n","    return {\"img\": normal_image, \"label\": batch[\"label\"]}\n","\n","def data_distributing(num_clients, bigdata, gamma):\n","    train_data = ddf(bigdata['train'][:40000])\n","    public_data = ddf(bigdata['train'][40000:])\n","    test_data = ddf(bigdata[\"test\"][:])\n","    Ds = []\n","    samples = np.random.dirichlet(np.ones(num_classes)*gamma, size=num_clients)\n","    num_samples = np.array(samples*int(len(train_data)/num_clients))\n","    num_samples = num_samples.astype(int)\n","    print(num_samples)\n","    for i in range(num_clients):\n","        idxs = []\n","        for c in range(num_classes):\n","            idxs.extend( np.random.choice( np.where(train_data[\"label\"]==c)[0], num_samples[i][c] ) )\n","        train_data_client = train_data[idxs]\n","        client_data = datasets.DatasetDict({  \"train\": ddf(train_data_client),  \"test\": test_data  })\n","        Ds.append(client_data)\n","    server_data = datasets.DatasetDict({ \"test\": test_data  })\n","    Ds.append(server_data)\n","    return Ds, public_data\n","\n","num_train_samples = 45000\n","num_test_samples = 1000\n","\n","# Loading Dataset\n","loaded_dataset = datasets.load_dataset(\"cifar10\", split=['train[:100%]', 'test[:100%]'])\n","num_classes = loaded_dataset[0].features[\"label\"].num_classes\n","name_classes = [\"{}\".format(name) for name in loaded_dataset[0].features[\"label\"].names]\n","Dataset1 = datasets.DatasetDict({   \"train\":ddf(loaded_dataset[0][shuffling(loaded_dataset[0].num_rows, num_train_samples)]),\"test\":ddf(loaded_dataset[1][shuffling(loaded_dataset[1].num_rows, num_test_samples)])   })\n","Dataset = datasets.DatasetDict({\"train\": ddf({'img': Dataset1[\"train\"][\"img\"], 'label': Dataset1[\"train\"][\"label\"]}),\\\n","                                 \"test\":  ddf({'img': Dataset1[\"test\"][\"img\"], 'label': Dataset1[\"test\"][\"label\"]})  })\n","\n","Dataset.set_format(\"torch\", columns=[\"img\", \"label\"])\n","Dataset = Dataset.map(normalization, batched=True)\n","\n","gamma = 10 # The parameter of Dirichlet distribution\n","Ds, public_data = data_distributing(10, Dataset, gamma)\n","\n","\n","\n","\n","class VGGBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(VGGBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","    def forward(self, x):\n","        x = nn.functional.relu(self.conv1(x))\n","        x = nn.functional.relu(self.conv2(x))\n","        x = self.pool(x)\n","        return x\n","\n","class LightWeight_CNN(nn.Module):\n","    def __init__(self, input_shape, output_shape, num_vcg):\n","        super().__init__()\n","        self.num_vcg = num_vcg\n","        self.vgg_block1 = VGGBlock(input_shape[0], 32)\n","        self.vgg_block2 = VGGBlock(32, 64)\n","        self.vgg_block3 = VGGBlock(64, 64)\n","        if self.num_vcg==1: self.fc1 = nn.Linear(int(input_shape[1]*input_shape[2]*32/4), 512)\n","        elif self.num_vcg==2: self.fc1 = nn.Linear(int(input_shape[1]*input_shape[2]*64/16), 512)\n","        elif self.num_vcg==3: self.fc1 = nn.Linear(int(input_shape[1]*input_shape[2]*64/64), 512)\n","        self.fc2 = nn.Linear(512, 128)\n","        self.fc3 = nn.Linear(128, 10)\n","    def forward(self, x):\n","        if self.num_vcg>=1:\n","            x = self.vgg_block1(x)\n","            if self.num_vcg>=2:\n","                x = self.vgg_block2(x)\n","                if self.num_vcg>=3:\n","                    x = self.vgg_block3(x)\n","        x = x.view(x.size(0), -1)\n","        x = nn.functional.relu(self.fc1(x))\n","        x = nn.functional.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","def adjust_temperature(p, T):\n","    modified_p = torch.zeros_like(p)\n","    for i in range(p.shape[0]):\n","        row = p[i]\n","        scaled_row = torch.pow(row, 1 / T)\n","        normalized_row = scaled_row / scaled_row.sum()\n","        modified_p[i] = normalized_row\n","    return modified_p\n","\n","class Prompt_Tuning_Model(torch.nn.Module):\n","  def __init__(self):\n","    super(Prompt_Tuning_Model, self).__init__()\n","    self.FM = FM\n","    for param in self.FM.parameters(): param.requires_grad = False\n","    self.num_prompts = num_prompts\n","    self.num_classes = num_classes\n","    self.name_classes = name_classes\n","    self.embedding_lookup_table = self.FM.text_model.embeddings\n","    self.ctx = torch.nn.Parameter(torch.nn.init.normal_(torch.empty(self.num_prompts, self.FM.config.text_config.hidden_size), std=0.02))\n","    self.ctx = torch.load(\"prompt.pt\", weights_only=True)\n","    self.build_token_embeds()\n","    self.logit_scale = torch.nn.Parameter(torch.tensor(self.FM.config.logit_scale_init_value))\n","    self.Loss = []\n","    self.Acc = []\n","    self.test_Acc = []\n","  def build_token_embeds(self):\n","    self.tokens = tokenizer(name_classes, add_special_tokens=True, padding=True, return_tensors=\"pt\")[\"input_ids\"]\n","    with torch.no_grad():\n","        self.token_embeds = self.embedding_lookup_table(self.tokens)\n","  def prepare_prompt(self):\n","    ctx = torch.unsqueeze(self.ctx, dim=0)\n","    ctx = torch.broadcast_to(ctx, [self.num_classes, ctx.shape[-2], ctx.shape[-1]])\n","    self.prompts = torch.cat([self.token_embeds[:, :1, :], ctx, self.token_embeds[:, 1:, :]], dim=1)\n","  def customize_images(self, imgs):\n","    if imgs.shape[1]==1: imgs = imgs.repeat(1,3,1,1)\n","    return processor( images=imgs, return_tensors=\"pt\", padding=True, do_rescale=False)['pixel_values']\n","  def __call__(self, images):\n","    self.prepare_prompt()\n","    output = self.FM.text_model.encoder(inputs_embeds = self.prompts)\n","    last_hidden_state = self.FM.text_model.final_layer_norm(output[0])\n","    pooled_output = last_hidden_state[torch.arange(last_hidden_state.shape[0]),  self.tokens.argmax(dim=-1)]\n","    text_rep = FM.text_projection(pooled_output)\n","\n","\n","    images = self.customize_images(images)\n","    img_rep = self.FM.get_image_features(images)\n","\n","    img_rep = img_rep / img_rep.norm(p=2, dim=-1, keepdim=True)\n","    text_rep = text_rep / text_rep.norm(p=2, dim=-1, keepdim=True)\n","\n","    logit_scale = self.logit_scale.exp()\n","    logits = logit_scale * img_rep @ text_rep.t()\n","    soft_labels = torch.nn.functional.softmax(logits, dim=1)\n","    return soft_labels\n","\n","\n","class Server():\n","    def __init__(self, clients, data):\n","        self.data = data\n","        self.clients = clients\n","        self.p_model = Prompt_Tuning_Model()\n","        self.Optimizer = torch.optim.Adam(self.p_model.parameters(),  lr=learning_rate)\n","        self.scheduler = CosineAnnealingLR(self.Optimizer, T_max=100, eta_min=0)\n","        self.Loss = []\n","        self.Acc = []\n","        #print(\"zero shot accuracy:\")\n","        #self.evaluate()\n","    def evaluate(self):\n","        imgs = self.data['test']['img']\n","        labels = self.data['test']['label']\n","        pred = self.p_model(imgs)\n","        acc = 0\n","        for i in range(len(labels)):\n","            if np.argmax(pred[i].detach().numpy()) == labels[i]: acc+=1\n","        print(\"Accuracy: \", acc*100/len(labels))\n","        self.Acc.append( acc*100/len(labels) )\n","    def aggregation(self, subset ):\n","        logits = torch.stack( [ nn.functional.softmax(client.model(subset[\"img\"]), dim=-1) for client in clients], dim=0)\n","        self.agg_soft_label = torch.mean(logits, dim=0)\n","    def get_global_knowledge(self, subset):\n","        imgs = subset['img']\n","        pred = self.p_model(imgs)\n","        self.global_knowledge = torch.nn.functional.softmax(pred, dim=1)\n","        return self.global_knowledge\n","    def prompt_tuning(self, subset):\n","        sl_data = ddf({ \"img\":subset['img'], \"label\":subset['label'] , \"agg_soft_label\":self.agg_soft_label  })\n","        dataset = torch.utils.data.DataLoader(sl_data, batch_size=server_batch_size, shuffle=True)\n","        epoch_loss = []\n","        for epoch in range(server_epochs):\n","            batch_loss = []\n","            self.p_model.train()\n","            for batch in dataset:\n","                self.Optimizer.zero_grad()\n","                pred = self.p_model( batch['img'] )\n","                t = adjust_temperature(batch[\"agg_soft_label\"], temp_fm)\n","                s = nn.functional.log_softmax(pred/temp_client , dim=-1)\n","                error1 = torch.nn.functional.cross_entropy(pred, batch[\"label\"])\n","                error2 = (temp**2)*nn.KLDivLoss( reduction='batchmean')(s, t)\n","                error = error1 + error2\n","                error.backward()\n","                self.Optimizer.step()\n","                batch_loss.append(float(error))\n","            self.scheduler.step()\n","            epoch_loss.append(np.mean(batch_loss))\n","            self.Loss.append(np.mean(batch_loss))\n","        self.evaluate()\n","    def FSL_data_preparing(self): #Few-Shot Learning data preparing\n","        labels = subset[\"label\"].detach().numpy()\n","        samples = subset[\"img\"].detach().numpy()\n","        classes = list(set(labels))\n","        new_samples = []\n","        new_labels = []\n","        for cls in classes :\n","            ins = np.where(np.array(labels)==cls)[0]\n","            ins = ins[ : min(num_shots, len(ins))]\n","            for i in ins:\n","                new_samples.append(samples[i])\n","                new_labels.append(cls)\n","        return  torch.tensor(new_samples),  torch.tensor(new_labels)\n","    def pre_prompt_tuning(self):\n","        new_samples, new_labels = self.FSL_data_preparing()\n","        sl_data = ddf({ \"img\":new_samples, \"label\":new_labels })\n","        dataset = torch.utils.data.DataLoader(sl_data, batch_size=server_batch_size, shuffle=True)\n","        epoch_loss = []\n","        for epoch in range(server_epochs):\n","            batch_loss = []\n","            self.p_model.train()\n","            for batch in dataset:\n","                self.Optimizer.zero_grad()\n","                pred = self.p_model( batch['img'] )\n","                error = torch.nn.functional.cross_entropy(pred, batch[\"label\"])\n","                error.backward()\n","                self.Optimizer.step()\n","                batch_loss.append(float(error))\n","            self.scheduler.step()\n","            epoch_loss.append(np.mean(batch_loss))\n","            self.Loss.append(np.mean(batch_loss))\n","            self.evaluate()\n","\n","\n","class Device():\n","    def __init__(self, id, data, num_vcg):\n","        self.id = id\n","        self.data = data\n","        input_shape = self.data['train']['img'][0].shape\n","        self.model = LightWeight_CNN(input_shape, num_classes, num_vcg)\n","        self.Optimizer = torch.optim.Adam(self.model.parameters(),  lr=learning_rate)\n","        self.scheduler = CosineAnnealingLR(self.Optimizer, T_max=100, eta_min=0)\n","        self.Loss = []\n","        self.Acc = []\n","    def evaluate(self):\n","        imgs = self.data['test']['img']\n","        labels = self.data['test']['label']\n","        pred = self.model(imgs)\n","        acc = 0\n","        for i in range(len(labels)):\n","            if np.argmax(pred[i].detach().numpy()) == labels[i]: acc+=1\n","        print(\"Accuracy: \", acc*100/len(labels))\n","        self.Acc.append( acc*100/len(labels) )\n","    def cal_softlabels(self):\n","        imgs = self.data['public']['img']\n","        pred = self.model(imgs)\n","        self.soft_labels = torch.nn.functional.softmax(pred, dim=1)\n","    def distillation(self, subset, global_knowledge):\n","        sl_data = ddf({   \"img\":subset['img'], \"label\":subset['label'], \"global_knowledge\":global_knowledge    })\n","        dataset = torch.utils.data.DataLoader(sl_data, batch_size=distil_batch_size, shuffle=True)\n","        epoch_loss = []\n","        for epoch in range(distil_epochs):\n","            batch_loss = []\n","            self.model.train()\n","            for batch in dataset:\n","                self.Optimizer.zero_grad()\n","                pred = self.model( batch['img'] )\n","                t = adjust_temperature(batch[\"global_knowledge\"], temp_fm)\n","                s = nn.functional.log_softmax(pred/temp_client , dim=-1)\n","                error1 = torch.nn.functional.cross_entropy(pred, batch[\"label\"])\n","                error2 = (temp**2)*nn.KLDivLoss( reduction='batchmean')(s, t)\n","                error = error1 + error2\n","                error.backward()\n","                self.Optimizer.step()\n","                batch_loss.append(float(error))\n","            self.scheduler.step()\n","            self.evaluate()\n","    def preparation(self, subset):\n","        dataset = torch.utils.data.DataLoader(subset, batch_size=pre_batch_size, shuffle=True)\n","        epoch_loss = []\n","        for epoch in range(pre_epochs):\n","            batch_loss = []\n","            self.model.train()\n","            for batch in dataset:\n","                self.Optimizer.zero_grad()\n","                pred = self.model( batch['img'] )\n","                error = torch.nn.functional.cross_entropy(pred, batch[\"label\"])\n","                error.backward()\n","                self.Optimizer.step()\n","                batch_loss.append(float(error))\n","            self.scheduler.step()\n","            epoch_loss.append(np.mean(batch_loss))\n","            self.Loss.append(np.mean(batch_loss))\n","            self.evaluate()\n","    def local_training(self):\n","        dataset = torch.utils.data.DataLoader(self.data[\"train\"], batch_size=local_batch_size, shuffle=True)\n","        epoch_loss = []\n","        for epoch in range(local_epochs):\n","            batch_loss = []\n","            self.model.train()\n","            for batch in dataset:\n","                self.Optimizer.zero_grad()\n","                pred = self.model( batch['img'] )\n","                error = torch.nn.functional.cross_entropy(pred, batch[\"label\"])\n","                error.backward()\n","                self.Optimizer.step()\n","                batch_loss.append(float(error))\n","            self.scheduler.step()\n","            epoch_loss.append(np.mean(batch_loss))\n","            self.Loss.append(np.mean(batch_loss))\n","            #print(f\"Loss of epoch {epoch}: {epoch_loss[-1]}\")\n","            self.evaluate()\n","\n","rounds = 20\n","num_clients = 10\n","\n","pre_epochs = 20\n","pre_batch_size = 256\n","\n","distil_epochs = 1\n","distil_batch_size = 32\n","\n","local_epochs = 1\n","local_batch_size = 16\n","\n","server_epochs = 4\n","server_batch_size = 256\n","num_prompts = 4\n","num_shots = 8\n","\n","learning_rate = 0.001\n","temp_fm = .1\n","temp_client = 10\n","\n","clients = [Device(id, Ds[id], 3) for id in range(num_clients)]\n","server = Server(clients, Ds[-1])\n","\n","subset = ddf(public_data[np.random.randint(0, len(public_data[\"label\"]), 1000)])\n","\n","\n","for client in clients:\n","    client.preparation(subset)\n","    client.local_training()\n","\n","server.pre_prompt_tuning()\n","\n","\n","for round in range(rounds):\n","    print(\"*\"*50, \"Round: {}\".format(round) ,\"*\"*50)\n","\n","    print(\"=\"*50 ,\"Prompt Tuning Phase\", \"\"*50)\n","    server.aggregation(subset)\n","    #server.prompt_tuning(subset)\n","\n","    print(\"=\"*50 ,\"Local Distillation Phase\", \"=\"*50)\n","    global_knowledge = server.get_global_knowledge(subset)\n","    for client in clients:\n","        print(\"-\"*30 ,\"Client {} knowledge distillation\".format(client.id), \"-\"*30)\n","        client.distillation(subset, global_knowledge) #FedD2P\n","        #client.distillation(subset, server.agg_soft_label) #FedMD\n","        #client.preparation(subset) #Local\n","\n","    print(\"=\"*50 ,\"Local Training Phase\", \"=\"*50)\n","    for client in clients:\n","        print(\"-\"*30 ,\"Client {} local training\".format(client.id), \"-\"*30)\n","        client.local_training()\n","\n","\n","\n","S = [client.Acc for client in clients]\n","\n","with open(\"S.pkl\", \"wb\") as file:\n","    pickle.dump(S, file)\n"]}]}