# -*- coding: utf-8 -*-
"""Whitepaper.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UDKO09tCO953ylGrSTy0ZyhN3-TCvquJ
"""

import numpy as np
import pandas as pd
import transformers
import sklearn.metrics
from huggingface_hub import notebook_login
import datasets
import tensorflow as tf
import torch
import torch.nn as nn
import keras
import matplotlib.pyplot as plt
from torch.optim.lr_scheduler import CosineAnnealingLR
#from PIL import Image
#import pickle


torch.manual_seed(42)
np.random.seed(42)

# Loading Foundation Model
model_name = "openai/clip-vit-base-patch32"
FM = transformers.CLIPModel.from_pretrained(model_name)
processor = transformers.CLIPProcessor.from_pretrained(model_name)
tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)



def ddf(x):
    x = datasets.Dataset.from_dict(x)
    x.set_format("torch")
    return x

def shuffling(a, b):
    return np.random.randint(0, a, b)

def normalization(batch):
    normal_image = batch["img"] / 255
    return {"img": normal_image, "label": batch["label"]}

def data_distributing(num_clients, bigdata, gamma):
    train_data = ddf(bigdata['train'][:40000])
    public_data = ddf(bigdata['train'][40000:])
    test_data = ddf(bigdata["test"][:])
    Ds = []
    samples = np.random.dirichlet(np.ones(num_classes)*gamma, size=num_clients)
    num_samples = np.array(samples*int(len(train_data)/num_clients))
    num_samples = num_samples.astype(int)
    print(num_samples)
    for i in range(num_clients):
        idxs = []
        for c in range(num_classes):
            idxs.extend( np.random.choice( np.where(train_data["label"]==c)[0], num_samples[i][c] ) )
        train_data_client = train_data[idxs]
        client_data = datasets.DatasetDict({  "train": ddf(train_data_client),  "test": test_data  })
        Ds.append(client_data)
    server_data = datasets.DatasetDict({ "test": test_data  })
    Ds.append(server_data)
    return Ds, public_data

num_train_samples = 45000
num_test_samples = 1000

# Loading Dataset
loaded_dataset = datasets.load_dataset("cifar10", split=['train[:100%]', 'test[:100%]'])
num_classes = loaded_dataset[0].features["label"].num_classes
name_classes = ["{}".format(name) for name in loaded_dataset[0].features["label"].names]
Dataset1 = datasets.DatasetDict({   "train":ddf(loaded_dataset[0][shuffling(loaded_dataset[0].num_rows, num_train_samples)]),"test":ddf(loaded_dataset[1][shuffling(loaded_dataset[1].num_rows, num_test_samples)])   })
Dataset = datasets.DatasetDict({"train": ddf({'img': Dataset1["train"]["img"], 'label': Dataset1["train"]["label"]}),\
                                 "test":  ddf({'img': Dataset1["test"]["img"], 'label': Dataset1["test"]["label"]})  })

Dataset.set_format("torch", columns=["img", "label"])
Dataset = Dataset.map(normalization, batched=True)

gamma = 10 # The parameter of Dirichlet distribution
Ds, public_data = data_distributing(10, Dataset, gamma)




class VGGBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(VGGBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
    def forward(self, x):
        x = nn.functional.relu(self.conv1(x))
        x = nn.functional.relu(self.conv2(x))
        x = self.pool(x)
        return x

class LightWeight_CNN(nn.Module):
    def __init__(self, input_shape, output_shape, num_vcg):
        super().__init__()
        self.num_vcg = num_vcg
        self.vgg_block1 = VGGBlock(input_shape[0], 64)
        self.vgg_block2 = VGGBlock(64, 64)
        self.vgg_block3 = VGGBlock(64, 128)
        if self.num_vcg==1: self.fc1 = nn.Linear(int(input_shape[1]*input_shape[2]*64/4), 512)
        elif self.num_vcg==2: self.fc1 = nn.Linear(int(input_shape[1]*input_shape[2]*64/16), 512)
        elif self.num_vcg==3: self.fc1 = nn.Linear(int(input_shape[1]*input_shape[2]*128/64), 512)
        self.fc2 = nn.Linear(512, 128)
        self.fc3 = nn.Linear(128, 10)
    def forward(self, x):
        if self.num_vcg>=1:
            x = self.vgg_block1(x)
            if self.num_vcg>=2:
                x = self.vgg_block2(x)
                if self.num_vcg>=3:
                    x = self.vgg_block3(x)
        x = x.view(x.size(0), -1)
        x = nn.functional.relu(self.fc1(x))
        x = nn.functional.relu(self.fc2(x))
        x = self.fc3(x)
        return x

def adjust_temperature(p, T):
    modified_p = torch.zeros_like(p)
    for i in range(p.shape[0]):
        row = p[i]
        scaled_row = torch.pow(row, 1 / T)
        normalized_row = scaled_row / scaled_row.sum()
        modified_p[i] = normalized_row
    return modified_p

class Prompt_Tuning_Model(torch.nn.Module):
  def __init__(self):
    super(Prompt_Tuning_Model, self).__init__()
    self.FM = FM
    for param in self.FM.parameters(): param.requires_grad = False
    self.num_prompts = num_prompts
    self.num_classes = num_classes
    self.name_classes = name_classes
    self.embedding_lookup_table = self.FM.text_model.embeddings
    self.ctx = torch.nn.Parameter(torch.nn.init.normal_(torch.empty(self.num_prompts, self.FM.config.text_config.hidden_size), std=0.02))
    self.build_token_embeds()
    self.logit_scale = torch.nn.Parameter(torch.tensor(self.FM.config.logit_scale_init_value))
    self.Loss = []
    self.Acc = []
    self.test_Acc = []
  def build_token_embeds(self):
    self.tokens = tokenizer(name_classes, add_special_tokens=True, padding=True, return_tensors="pt")["input_ids"]
    with torch.no_grad():
        self.token_embeds = self.embedding_lookup_table(self.tokens)
  def prepare_prompt(self):
    ctx = torch.unsqueeze(self.ctx, dim=0)
    ctx = torch.broadcast_to(ctx, [self.num_classes, ctx.shape[-2], ctx.shape[-1]])
    self.prompts = torch.cat([self.token_embeds[:, :1, :], ctx, self.token_embeds[:, 1:, :]], dim=1)
  def customize_images(self, imgs):
    if imgs.shape[1]==1: imgs = imgs.repeat(1,3,1,1)
    return processor( images=imgs, return_tensors="pt", padding=True, do_rescale=False)['pixel_values']
  def __call__(self, images):
    self.prepare_prompt()
    output = self.FM.text_model.encoder(inputs_embeds = self.prompts)
    last_hidden_state = self.FM.text_model.final_layer_norm(output[0])
    pooled_output = last_hidden_state[torch.arange(last_hidden_state.shape[0]),  self.tokens.argmax(dim=-1)]
    text_rep = FM.text_projection(pooled_output)


    images = self.customize_images(images)
    img_rep = self.FM.get_image_features(images)

    img_rep = img_rep / img_rep.norm(p=2, dim=-1, keepdim=True)
    text_rep = text_rep / text_rep.norm(p=2, dim=-1, keepdim=True)

    logit_scale = self.logit_scale.exp()
    logits = logit_scale * img_rep @ text_rep.t()
    soft_labels = torch.nn.functional.softmax(logits, dim=1)
    return soft_labels


class Server():
    def __init__(self, clients, data):
        self.data = data
        self.clients = clients
        self.p_model = Prompt_Tuning_Model()
        self.Optimizer = torch.optim.Adam(self.p_model.parameters(),  lr=learning_rate)
        self.scheduler = CosineAnnealingLR(self.Optimizer, T_max=100, eta_min=0)
        self.Loss = []
        self.Acc = []
        #print("zero shot accuracy:")
        #self.evaluate()
    def evaluate(self):
        imgs = self.data['test']['img']
        labels = self.data['test']['label']
        pred = self.p_model(imgs)
        acc = 0
        for i in range(len(labels)):
            if np.argmax(pred[i].detach().numpy()) == labels[i]: acc+=1
        print("Accuracy: ", acc*100/len(labels))
        self.Acc.append( acc*100/len(labels) )
    def aggregation(self, subset ):
        logits = torch.stack( [ nn.functional.softmax(client.model(subset["img"]), dim=-1) for client in clients], dim=0)
        self.agg_soft_label = torch.mean(logits, dim=0)
    def get_global_knowledge(self, subset):
        imgs = subset['img']
        pred = self.p_model(imgs)
        self.global_knowledge = torch.nn.functional.softmax(pred, dim=1)
        return self.global_knowledge
    def prompt_tuning(self, subset):
        sl_data = ddf({ "img":subset['img'], "label":subset['label'] , "agg_soft_label":self.agg_soft_label  })
        dataset = torch.utils.data.DataLoader(sl_data, batch_size=server_batch_size, shuffle=True)
        epoch_loss = []
        for epoch in range(server_epochs):
            batch_loss = []
            self.p_model.train()
            for batch in dataset:
                self.Optimizer.zero_grad()
                pred = self.p_model( batch['img'] )
                t = adjust_temperature(batch["agg_soft_label"], temp_client)
                s = nn.functional.log_softmax(pred/temp_fm , dim=-1)
                error1 = torch.nn.functional.cross_entropy(pred, batch["label"])
                error2 = nn.KLDivLoss( reduction='batchmean')(s, t)
                error = error1 + error2
                error.backward()
                self.Optimizer.step()
                batch_loss.append(float(error))
            self.scheduler.step()
            epoch_loss.append(np.mean(batch_loss))
            self.Loss.append(np.mean(batch_loss))
        self.evaluate()
    def FSL_data_preparing(self): #Few-Shot Learning data preparing
        labels = subset["label"].detach().numpy()
        samples = subset["img"].detach().numpy()
        classes = list(set(labels))
        new_samples = []
        new_labels = []
        for cls in classes :
            ins = np.where(np.array(labels)==cls)[0]
            ins = ins[ : min(num_shots, len(ins))]
            for i in ins:
                new_samples.append(samples[i])
                new_labels.append(cls)
        return  torch.tensor(new_samples),  torch.tensor(new_labels)
    def pre_prompt_tuning(self):
        new_samples, new_labels = self.FSL_data_preparing()
        sl_data = ddf({ "img":new_samples, "label":new_labels })
        dataset = torch.utils.data.DataLoader(sl_data, batch_size=server_batch_size, shuffle=True)
        epoch_loss = []
        for epoch in range(server_epochs):
            batch_loss = []
            self.p_model.train()
            for batch in dataset:
                self.Optimizer.zero_grad()
                pred = self.p_model( batch['img'] )
                error = torch.nn.functional.cross_entropy(pred, batch["label"])
                error.backward()
                self.Optimizer.step()
                batch_loss.append(float(error))
            self.scheduler.step()
            epoch_loss.append(np.mean(batch_loss))
            self.Loss.append(np.mean(batch_loss))
            self.evaluate()


class Device():
    def __init__(self, id, data, num_vcg):
        self.id = id
        self.data = data
        input_shape = self.data['train']['img'][0].shape
        self.model = LightWeight_CNN(input_shape, num_classes, num_vcg)
        self.Optimizer = torch.optim.Adam(self.model.parameters(),  lr=learning_rate)
        self.scheduler = CosineAnnealingLR(self.Optimizer, T_max=100, eta_min=0)
        self.Loss = []
        self.Acc = []
    def evaluate(self):
        imgs = self.data['test']['img']
        labels = self.data['test']['label']
        pred = self.model(imgs)
        acc = 0
        for i in range(len(labels)):
            if np.argmax(pred[i].detach().numpy()) == labels[i]: acc+=1
        print("Accuracy: ", acc*100/len(labels))
        self.Acc.append( acc*100/len(labels) )
    def cal_softlabels(self):
        imgs = self.data['public']['img']
        pred = self.model(imgs)
        self.soft_labels = torch.nn.functional.softmax(pred, dim=1)
    def distillation(self, subset, global_knowledge):
        sl_data = ddf({   "img":subset['img'], "label":subset['label'], "global_knowledge":global_knowledge    })
        dataset = torch.utils.data.DataLoader(sl_data, batch_size=distil_batch_size, shuffle=True)
        epoch_loss = []
        for epoch in range(distil_epochs):
            batch_loss = []
            self.model.train()
            for batch in dataset:
                self.Optimizer.zero_grad()
                pred = self.model( batch['img'] )
                t = adjust_temperature(batch["global_knowledge"], temp_fm)
                s = nn.functional.log_softmax(pred/temp_client , dim=-1)
                error1 = torch.nn.functional.cross_entropy(pred, batch["label"])
                error2 = (temp_client**2)*nn.KLDivLoss( reduction='batchmean')(s, t)
                error = error1 + error2
                error.backward()
                self.Optimizer.step()
                batch_loss.append(float(error))
            self.scheduler.step()
            self.evaluate()
    def preparation(self, subset):
        dataset = torch.utils.data.DataLoader(subset, batch_size=pre_batch_size, shuffle=True)
        epoch_loss = []
        for epoch in range(pre_epochs):
            batch_loss = []
            self.model.train()
            for batch in dataset:
                self.Optimizer.zero_grad()
                pred = self.model( batch['img'] )
                error = torch.nn.functional.cross_entropy(pred, batch["label"])
                error.backward()
                self.Optimizer.step()
                batch_loss.append(float(error))
            self.scheduler.step()
            epoch_loss.append(np.mean(batch_loss))
            self.Loss.append(np.mean(batch_loss))
            self.evaluate()
    def local_training(self):
        dataset = torch.utils.data.DataLoader(self.data["train"], batch_size=local_batch_size, shuffle=True)
        epoch_loss = []
        for epoch in range(local_epochs):
            batch_loss = []
            self.model.train()
            for batch in dataset:
                self.Optimizer.zero_grad()
                pred = self.model( batch['img'] )
                error = torch.nn.functional.cross_entropy(pred, batch["label"])
                error.backward()
                self.Optimizer.step()
                batch_loss.append(float(error))
            self.scheduler.step()
            epoch_loss.append(np.mean(batch_loss))
            self.Loss.append(np.mean(batch_loss))
            #print(f"Loss of epoch {epoch}: {epoch_loss[-1]}")
            self.evaluate()

rounds = 20
num_clients = 10

pre_epochs = 20
pre_batch_size = 256

distil_epochs = 1
distil_batch_size = 32

local_epochs = 1
local_batch_size = 16

server_epochs = 4
server_batch_size = 256
num_prompts = 4
num_shots = 8

learning_rate = 0.001
temp_fm = .1
temp_client = 10

clients = [Device(id, Ds[id], 3) for id in range(num_clients)]
server = Server(clients, Ds[-1])

subset = ddf(public_data[np.random.randint(0, len(public_data["label"]), 1000)])


for client in clients:
    client.preparation(subset)
    client.local_training()

server.pre_prompt_tuning()


for round in range(rounds):
    print("*"*50, "Round: {}".format(round) ,"*"*50)

    print("="*50 ,"Prompt Tuning Phase", ""*50)
    server.aggregation(subset)
    server.prompt_tuning(subset)

    print("="*50 ,"Local Distillation Phase", "="*50)
    global_knowledge = server.get_global_knowledge(subset)
    for client in clients:
        print("-"*30 ,"Client {} knowledge distillation".format(client.id), "-"*30)
        client.distillation(subset, global_knowledge) #FedD2P
        #client.distillation(subset, server.agg_soft_label) #FedMD
        #client.preparation(subset) #Local

    print("="*50 ,"Local Training Phase", "="*50)
    for client in clients:
        print("-"*30 ,"Client {} local training".format(client.id), "-"*30)
        client.local_training()



S = [client.Acc for client in clients]

#with open("S.pkl", "wb") as file:
  #  pickle.dump(S, file)
